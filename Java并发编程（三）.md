# Java并发编程（三）

标签（空格分隔）： java 并发编程

---
<h1>第十章  避免活跃性危险</h1>

<h2>1.死锁</h2>
定义：在线程A持有锁L并想获得锁M的同时，线程B持有锁M并尝试获得锁L，线程AB均不会释放自己的锁，那么这两个线程将永远地等待下去</br>

在数据库系统的设中考虑了检测死锁以及从死锁中恢复。JVM没有办法解决死锁，只能在编程和测试时注意不要让死锁发生</br>
（1）锁顺序死锁————两个线程试图以不同的顺序来获得相同的锁</br>

解决：如果所有线程以固定的顺序来获得锁，那么在程序中就不会出现锁顺序死锁问题。</br>

（2） 动态的锁顺序死锁  </br>

使用Account中包含的唯一的不可变的并且具备可比性的键值或计算HashCode作为加锁顺序的依据。</br>

（3）在协作对象间发生死锁</br>

如果在持有锁时调用某个外部方法，那么将出现活跃性问题。在这个外部方法中可能会获取其他锁（这可能会产生死锁），或者阻塞时间过长，导致其他线程无法及时获得当前被持有的锁。</br>

（4）开放调用————在调用某个方法时不需要持有锁</br>

在程序中应尽量使用开放调用。与那些在持有锁时调用外部方法的程序相比，更易于对依赖于开放调用的程序进行死锁分析。</br>

（5）资源死锁——两个线程分别持有彼此想要的资源而又不会释放</br>

例：任务执行需要连接两个数据库，两个任务分别连接了其中一个数据库，而又等待彼此释放另一个数据库的资源

（6）线程饥饿死锁——一个任务中提交另一个任务，并一直等待被提交任务完成</br>

这些任务往往是产生线程饥饿死锁的主要来源，有界线程池 / 资源池与相互依赖的任务不能一起使用。</br>

<h2>2.死锁的避免与诊断</h2>
如果一个线程每次至多只能获得一个锁，那么就不会产生锁顺序死锁。</br>

如果必须获取多个锁，那么在设计时必须考虑锁的顺序：尽量减少潜在的加锁交互数量，将获取锁时需要遵循的协议写入正式文档并始终遵循这些文档。</br>

（1）支持定时锁</br>

显式使用Lock类中的定时tryLock功能来代替内置锁机制，显式锁则可以指定一个超时时限，在等待超过该时间后tryLock会返回一个失败信息。</br>

当定时锁失败时，并不能确定是否由于死锁导致失败。
即使不使用定时锁，使用能定时的锁，如果在获取锁时超时，那么可以释放当前的锁，在一段时间后再次尝试，从而消除了死锁发生的条件（在同时获取两个锁时有效）。</br>


（2）通过线程转储信息来分析死锁</br>

　　线程转储包括各个运行中的线程的栈追踪信息，这类似于发生异常时的栈追踪信息。线程转储还包括加锁信息，例如每个线程持有了哪些锁，在哪些栈帧中获得这些锁，以及被阻塞的线程正在等待获取哪一个锁。在生成线程转储之前，JVM将在等待关系图通过循环来找出死锁。如果发现了一个死锁，则获取相应的死锁信息，例如在死锁中涉及哪些锁和线程，以及这个锁的获取操作位于程序的哪些位置。</br>

　　显式锁比在内置锁上获得的信息精确度低。内置锁与获得它们所在的线程栈帧是相关联的，而显式的Lock只与获得它的线程相关联</br>


<h2>3.其他活跃性危险</h2>
（1）饥饿————线程由于无法访问它所需要的资源时而不能继续执行</br>

例：持有锁时执行一些无法结束的结构；低优先级的任务获取不到CPU资源</br>

要避免使用线程优先级，因为这会增加平台依赖性，并可能导致活跃性问题。在大多数并发应用程序中，都可以使用默认的线程优先级</br>


（2）糟糕的响应性   </br>

例：后台任务若为CPU密集型，将可能影响程序响应性</br>

例：不良的锁管理，某个锁持有过长时间</br>

（3）活锁</br>
例：错误的事务运行失败放在队列头</br>

例：多个相互协作的线程都对彼此进行响应从而修改各自的状态，并使得任何一个线程都无法继续执行（通过等待随机长度的时间和回退可以有效的避免活锁）</br>





<h1>第十一章  性能和可伸缩性</h1>

<h2>1.对性能的思考</h2>
提升性能意味着用更少的资源做更多地事情。要想通过并发来获得更好的性能，就要更有效地利用现有处理资源。</br>
线程使用的额外的性能开销：线程之间的协调（例如加锁、触发信号以及内存同步等），增加的上下文切换，线程的创建和销毁，以及线程的调度。等</br>

（1）性能与可伸缩性（多快vs多少）</br>
性能通过服务时间、延迟时间、吞吐率、效率、可伸缩性以及容量等衡量</br>

当进行性能调优时，其目的通常是用更小的代价完成相同的工作 </br>

可伸缩性指的是：当增加计算资源时（例如CPU、内存、存储容量或I/O带宽），程序的吞吐量或者处理能力响应地增加</br>

在进行可伸缩性调优时，其目的是设法将问题的计算并行化，从而能利用更多地计算资源来完成更多的工作。</br>

我们通常会接受每个工作单元执行更长的时间或消耗更多的计算资源，以换取应用程序在增加更多资源的情况下处理更高的负载。（多少更重要）</br>


（2）评估各种性能权衡因素</br>
”更快“的含义是什么？</br>
该方法在什么条件下运行得更快？在低负载还是高负载的情况下？大数据集还是小数据集？能否通过测试结果来验证你的答案？</br>
这些条件在运行环境中的发生频率？能否通过测试结果来验证你的答案？</br>
在其他不同条件的环境中能否使用这里的代码？</br>
在实现这种性能提升时需要付出哪些隐含地代价，例如增加开发风险或维护开销？这种权衡是否合适？</br>
在对性能的调优时，一定要有明确的性能需求</br>




<h2>2.Amdahl定律</h2>
Amdahl定律描述的是：在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于程序中可并行组件与串行组件所占的比重。</br>

Speedup <= 1 / (F + (1 - F) / N) ------- F是必须被串行执行的部分所占比例，N是机器中含有处理器的个数</br>

当N趋近无穷大时，最大的加速比趋近于1/F</br>
如下图，串行比例越高的程序到达瓶颈需要的处理器数越少，瓶颈的处理器利用率越低</br>

在所有并发程序中都存在串行部分（例：存储结果的共享容器，从共享队列中取出任务）</br>

（1）框架中隐藏着串行部分</br>

通过比较当增加线程时吞吐量的变化，推断出框架中串行部分所占比例</br>
synchronizedLinkedList比concurrentlinekedlist有更高的串行比例，更容易到达瓶颈，最高加速比更低</br>
到达瓶颈后小幅的下降表示增多线程时加速比的提高已经小于由于线程切换带来性能的损失</br>

（2）Amdahl定律的应用</br>

串行执行比例 => 最大加速比 => 达到最大加速比的线程数量</br>


<h2>3.线程引入的开销</h2>

多个线程的调度和协调过程总都需要一定的性能开销：对于为了提升性能而引入的线程来说，并行带来的性能提升必须超过并发导致的开销。</br>

（1）上下文切换</br>

过程：保存当前运行线程的执行上下文，并将新调度进来的线程的上下文设置为当前上下文</br>
切换上下文需要一定的开销，而在线程调度过程中需要访问操作系统和JVM共享的数据结构</br>
上下文切换将导致一些缓存缺失，因而线程在首次调度运行时会更加缓慢</br>

（2）内存同步</br>

内存栅栏：在synchronized和volatile提供的可见性保证中可能会使用一些特殊指令</br>
内存栅栏可以刷新缓存，在内存栅栏中，大多数操作都是不能被重排序的</br>
解决：</br>
JVM优化去掉不会发生竞争的锁</br>
找出不需同步的本地栈元素</br>
锁粒度粗化，将近邻的锁合并，减少锁请求和锁释放的次数</br>


（3）阻塞——当在锁上发生竞争时，竞争失败的线程肯定会阻塞</br>  自旋等待——通过循环不断地尝试获取锁</br>
挂起——产生额外上下文开销</br>



<h2>4.减少锁的竞争</h2>
并发程序中，对可伸缩性的最主要威胁就是独占方式的资源锁。（锁的请求频率 + 每次持有该锁的时间）</br> 

（1）缩小锁的范围（“快进快出”）</br> 

　　目标：尽可能缩短持有锁的时间</br> 

　　方法：超出共享变量，只对操作共享变量的代码加锁</br> 

　　理论：根据Amdahl定律，减少了必须串行执行的部分</br> 

　　注意：必要的原子操作不能分别加锁；锁粒度细化造成更多的同步开销，JVM会自动进行锁粒度粗化</br> 

（2）减少锁粒度——是不同组对象持有不同的锁</br> 

锁分解：如果一个锁需要保护多个相互独立的状态变量，那么可以将这个锁分解为多个锁，并且每个锁只保护一个变量，从而提高可伸缩性，并最终降低每个锁被请求的频率。</br> 

对锁分解后每个新的细粒度锁上的访问将减少，分摊到两个锁上。</br> 

对竞争适中的锁进行分解时，实际上是把这些锁转变为”非竞争“的锁，从而有效地提高性能和可伸缩性</br> 



（3）锁分段——对一组独立对象上的锁分解</br> 

对竞争激烈的锁进行分解时，两个锁可能竞争仍很激励，性能提高不明显</br> 

 

例：在ConcurrentHashMap的实现中使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16，其中第N个散列桶由第（N mod 16）个锁来保护。</br> 

挑战：有些操作需要独占整个对象，即需要全部的锁，这样开销更大。但有些操作即使需要获得全部的锁，但也不需要同时获得。</br> 


（4）避免热点区域</br> 

如果程序采用锁分段或分解技术，那么一定要表现出在锁上的竞争频率高于在锁保护的数据上发生竞争的频率（例：ConcurrentHashMap和Map中的每一項）</br> 

热点域：数据上发生很高频率的竞争（例：HashMap.size()）</br> 

解决：ConcurrentHashMap为每个分段都维护一个独立的size计数，并通过每个分段的锁来维护总size。</br> 

（5）代替独占锁的方法</br> 

　　ReadWriteLock：如果多个读取操作都不会修改共享资源，那么这些读取操作可以同时访问该共享资源，但在执行写入操作时必须以独占方式来获取锁</br> 

　　原子变量：降低更新“热点域”时的开销，例如竞态计数器、序列发生器、或者对链表数据结构中头节点的引用。原子变量类提供了在整数或者对象引用上的细粒度原子操作（因此可伸缩性更高），并使用了现代处理器中提供的底层并发原语（例如比较并交换）</br> 
　　
　　
（6）监控CPU利用率

　　linux命令：vmstat或mpstat</br> 

cpu利用不充分的原因：</br> 

负载不充足。</br> 
I/O密集。*nix可用iostat, windows用perfmon。</br> 
外部限制。如数据库服务，web服务等。</br> 
锁竞争。可通过jstack等查看栈信息。</br> 
如果CPU的利用率很高，并且总会有可运行的线程在等待CPU，那么当增加更多地处理器时，程序的性能可能会得到提升。</br> 


（8）对对象池说不</br> 

　　当线程分配新的对象时，基本上不需要在线程之间进行协调，因为对象分配器通常会使用线程本地的内存块，所以不需要在堆数据结构上进行同步。然而，如果这些线程从对象池中请求一个对象，那么就需要通过某种同步来协调对象池数据结构的访问，从而使某个线程被阻塞。</br> 

对象分配操作的开销比同步的开销更低。</br> 



<h2>5.减少上下文切换的开销</h2>
减少锁的持有时间，因为持有时间越长，就越容易发生竞争，就月容易发生阻塞。当任务在运行和阻塞这两个状态之间转换时，就相当于一次上下文切换。 </br> 


<h1>第十二章  并发程序的测试</h1>

<h2>1.正确性测试</h2>
重点：找出需要检查的不变性条件和后验条件。 </br>

（1）对基本单元的测试——串行的执行。</br>

（2）对阻塞操作的测试</br>
每个测试必须等他创建的所有线程结束后才可以结束（join）</br>

要测试一个方法的阻塞行为，类似于测试一个抛出异常的方法：如果这个方法可以正常返回，那么就意味着测试失败。</br>

在测试方法的阻塞行为时，将引入额外的复杂性：当方法被成功地阻塞后，还必须使方法解除阻塞。（中断）</br>

（3）安全性测试</br>

　　构建对并发类的安全性测试中，需要解决的关键问题在于，要找出那些容易检查的属性，这些属性在发生错误的情况下极有可能失败，同时又不会使得错误检查代码人为地限制并发性。理想的情况是，在测试属性中不需要任何同步机制。</br>

例：通过计算入列和出列的校验和进行检验（使用栅栏保证线程均运行到可检验处再检验）。</br>

（4）资源管理测试</br>

对于任何持有或管理其他对象的对象，都应该在不需要这些对象时销毁对它们的引用。</br>

例：使用堆检验工具对内存资源使用进行检验。</br>

（5）使用回调</br>

可以通过自定义扩展类来进行相关测试。</br>


（6）产生更多的交替操作</br>

使用yield、sleep命令更容易使错误出现</br>



<h2>2.性能测试</h2>
性能测试的目标：</br>

衡量典型测试用例中的端到端性能，获得合理的使用场景</br>
根据经验值来调整各种不同的限值，如线程数量，缓存容量等</br>


（1）计时器</br>
通过增加计时器，并改变各个参数、线程池大小、缓存大小，计算出运行时间</br>

（2）多种算法的比较</br>
使用不同的内部实现算法，找出具有更高的可伸缩性的算法</br>

（3）响应性衡量</br>

某个动作经过多长时间才能执行完成，这时就要测量服务时间的变化情况</br>

除非线程由于密集的同步需求而被持续的阻塞，否则非公平的信号量通常能实现更好的吞吐量，而公平的信号量则实现更低的变动性（公平性开销主要由于线程阻塞所引起）</br>




<h2>3.避免性能测试的陷阱</h2>
（1）垃圾回收</br>
保证垃圾回收在执行测试程序期间不被执行，可通过-verbose:gc查看垃圾回收信息。</br>
保证垃圾回收在执行测试程序期间执行多次，可以充分反映出运行期间的内存分配和垃圾回收等开销。</br>

（2）动态编译</br>
可以让测试程序运行足够长时间，防止动态编译对测试结果产生的偏差。</br>
在HotSpot中设置-xx：+PrintCompilation，在动态编译时输出一条信息</br>

（3）对代码路径不真实采样</br>
动态编译可能会让不同地方调用的同一方法生成的代码不同</br>
测试程序不仅要大致判断某个典型应用程序的使用模式，还要尽量覆盖在该应用程序中将执行的代码路径集合</br>

（4）不真实的竞争程度</br>
不同的共享数据和执行本地计算的比例，将表现出不同的竞争程度，也就有不同的性能和可伸缩性</br>

（5）无用代码的消除</br>
编译器可能会删除那些没有意义或不会产生结果或可预测结果的代码</br>
使结果尽量是不可预测的</br>




<h2>4.其他测试方法</h2>
代码审查（人工检查代码），竞态分析工具（FindBugs，CheckStyle），面向方面的测试技术，分析与检测工具（jvisualvm）。 </br>






<h1>第十三章  显式锁</h1>


<h2>1.Lock与ReentrantLock</h2>
Lock接口中定义了一种无条件、可轮询的、定时的以及可中断的锁获取操作，所有加锁和解锁的方法都是显式的。</br>

ReentrantLock实现了Lock接口，并提供了与synchronized相同的互斥性和内存可见性。ReentrantLock同样提供了可重入的加锁语义。</br>

（1）轮询锁与定时锁</br>

轮询锁和定时锁可由tryLock来实现</br>
轮询锁，定时锁可以避免死锁的发生</br>
轮询锁通过释放已获得的锁，并退回重新尝试获取所有锁（lock.tryLock()），定时锁通过释放已获得的锁，放弃本次操作（lock.tryLock(timeout, unit)）来避免死锁</br>


（2）可中断的锁获取操作</br>
Lock.lockInterruptibly()：该锁与lock相似，但可以被中断</br>
如果线程未被中断，也不能获取到锁，就会一直阻塞下去，直到获取到锁或发生中断请求</br>
定时的lock.tryLock(timeout, unit)同样能响应中断</br>


（3）非块结构加锁</br>

内置锁是基于块结构的加锁</br>
Lock可以使块与块交叉实现非块结构的加锁（连锁式加锁或者锁耦合），例：链表中，next节点加锁后，释放pre节点的锁</br>



<h2>2.性能考虑因素</h2>
竞争性能是可伸缩性的关键因素：如果有越多的资源被耗费在锁的管理和调度上，那么应用程序得到的资源就越少</br>

在Java5.0中，ReentrantLock能提供更高的吞吐量，但在Java6中，二者的吞吐量非常接近</br>



<h2>3.公平性</h2>
公平锁——Lock fairLock = new ReentrantLock(true); </br>

在公平的锁上，线程将按照它们发出请求的顺序来获得锁</br>
在非公平的锁上，则允许”插队“：当一个线程请求非公平的锁时，如果在发出请求的同时该锁的状态变为可用，那么这个线程将跳过队列中所有的等待线程并获得这个锁</br>
公平性将由于在挂起线程和恢复线程时存在的开销而极大地降低性能（非公平性的锁允许线程在其他线程的恢复阶段进入加锁代码块）</br>
当持有锁的时间相对较长，或者请求锁的平局时间间隔较长，那么应该使用公平锁</br>
内置锁默认为非公平锁</br>


<h2>4.在Synchronized和ReentrantLock之间作出选择</h2>
在一些内置锁无法满足需求的情况下，ReentrantLock可以作为一种高级工具。当需要一些高级功能时才应该使用ReentrantLock，这些功能包括：可定时的、可轮询的与可中断的锁获取操作，公平队列，以及非块结构的锁。否则，还是应该优先使用synchronized</br>

　　Synchronized是JVM的内置属性，能执行一些优化，并且基于块结构与特定栈管理，便于检测识别发生死锁。</br>

　　Java6提供了一个管理和调试接口，锁可以通过该接口进行注册，从而与ReentrantLocks相关的加锁信息就能出现在转储中，并通过其他的管理接口和调试接口来访问。</br>
　　
　　
<h2>5.读—写锁</h2>
对于在多处理器系统上被频繁读取的数据结构，读 - 写锁能够提高性能。而在其他情况下，读 - 写锁的性能比独占锁的性能要略差一些，这是因为它们的复杂性更高。</br>

读写锁的可选实现：</br>

释放优先。写入锁释放后，应该优先选择读线程，写线程，还是最先发出请求的线程。</br>
读线程插队。锁由读线程持有，写线程再等待，再来一个读线程，是继续让读线程访问，还是让写线程访问
重入性。读取锁和写入锁是否可重入。</br>
降级。将写入锁降级为读取锁。</br>
升级。将读取锁升级为写入锁。</br>

在非公平的锁中，线程获得访问许可的顺序是不确定的。写线程降级为读线程是可以的，当从读线程升级为写线程这是不可以的（这样会导致死锁）。






<h1>第十四章  构建自定义的同步工具</h1>



<h2>1.状态依赖性管理</h2>

对于单线程程序，某个条件为假，那么这个条件将永远无法成真</br>
在并发程序中，基于状态的条件可能会由于其他线程的操作而改变</br>

（1）将前提条件的失败传递给调用者 </br>
（2）通过轮询与休眠来实现简单的阻塞</br>
（3）条件队列——使得一组线程（称之为等待线程集合）能够通过某种方式来等待特定的条件变成真（元素是一个个正在等待相关条件的线程）。</br>

每个对象都可以作为一个条件队列（API：wait、notify和notifyAll)。</br>
Object.wait会自动释放锁，并请求操作系统挂起当前线程，从而使其他线程能够获得这个锁并且修改对象的状态。</br>
Object.notify/notifyAll通知被挂起的线程可以重新请求资源执行。</br>
只有能对状态进行检查时，才能在某个条件上等待，并且只有能修改状态时，才能从条件等待中释放另一个线程。</br>
条件队列在CPU效率、上下文切换开销和响应性等进行了优化。</br>
如果某个功能无法通过“轮询和休眠”来实现，那么使用条件队列也无法实现。</br>


<h2>2.使用条件队列</h2>
（1）条件谓词</br>

条件等待中存在一种重要的三元关系，包括加锁、wait方法和一个条件谓词</br>
条件谓词是由类中各个状态变量构成的表达式（while）</br>
在测试条件谓词之前必须先持有这个锁</br>
锁对象与条件队列对象（即调用wait和notify等方法所在的对象）必须是同一个对象</br>
wait被唤醒后需要重新获得锁，并重新检查条件谓词</br>

（2）过早唤醒——一个条件队列与多个条件谓词相关时，wait方法返回不一定线程所等待的条件谓词就变为真了</br>

当使用条件等待时(如Object.wait(), 或Condition.await())：</br>

通常都有一个条件谓词--包括一些对象状态的测试，线程在执行前必须首先通过这些测试</br>
在调用wait之前测试条件谓词，并且从wait中返回时再次进行测试</br>
在一个循环中调用wait</br>
确保使用与条件队列相关的锁来保护构成条件谓词的各个状态变量</br>
当调用wait, notify或notifyAll等方法时，一定要持有与条件队列相关的锁</br>
在检查条件谓词之后以及开始执行相应的操作之前，不要释放锁。</br>


（3）丢失信号量——线程必须等待一个已经为真的条件，但在开始等待之前没有检查条件谓词</br>

如果线程A通知了一个条件队列，而线程B随后在这个条件队列上等待，那么线程B将不会立即醒来，而是需要另一个通知来唤醒它（导致活跃性下降）</br>


（4）通知——确保在条件谓词变为真时通过某种方式发出通知挂起的线程</br>

发出通知的线程持有锁调用notify和notifyAll，发出通知后应尽快释放锁</br>
多个线程可以基于不同的条件谓词在同一个条件队列上等待，使用notify单一的通知很容易导致类似于信号丢失的问题</br>
可以使用notify：同一条件谓词并且单进单出</br>
使用notifyAll有时是低效的：唤醒的所有线程都需要竞争锁，并重新检验，而有时最终只有一个线程能执行</br>

优化：条件通知</br>

（5）示例：阀门类</br>
arrivalGeneration == generation为了保证在阀门打开时又立即关闭时，在打开时通知的线程都可以通过阀门</br>

（6）子类的安全问题</br>

如果在实施子类化时违背了条件通知或单词通知的某个需求，那么在子类中可以增加合适的通知机制来代表基类。</br>
对于状态依赖的类，要么将其等待和通知等协议完全向子类公开（并且写入正式文档），要么完全阻止子类参与到等待和通知等过程中。</br>
完全禁止子类化。</br>

（7）封装条件队列</br>

（8）入口协议和出口协议</br>

入口协议：该操作的条件谓词。</br>
出口协议：检查被该操作修改的所有状态变量，并确认它们是否使某个其他的条件谓词变为真，如果是，则通知相关的条件队列。</br>


<h2>3.显示的Condition对象</h2>
内置条件队列的缺点：每个内置锁都只能有一个相关联的条件队列，而多个线程可能在同一条件队列上等待不同的条件谓词，调用notifyAll通知的线程非等待同义谓词</br>

Condition <-> Lock，内置条件队列 <-> 内置锁</br>

Lock.newCondition()</br>
在每个锁上可存在多个等待、条件等待可以是可中断的或不可中断的、基于时限的等待，以及公平的或非公平的队列操作</br>
Condition对象继承了相关的Lock对象的公平性</br>
与wait、notify和notifyAll方法对应的分别是await、signal和signalAll</br>
将多个条件谓词分开并放到多个等待线程集，Condition使其更容易满足单次通知的需求（signal比signalAll更高效）</br>

锁、条件谓词和条件变量：件谓词中包含的变量必须由Lock来保护，并且在检查条件谓词以及调用await和signal时，必须持有Lock对象</br>


<h2>4.Synchronizer解析</h2>
在ReentrantLock和Semaphore这两个接口之间存在许多共同点。两个类都可以用作一个”阀门“，即每次只允许一定数量的线程通过，并当线程到达阀门时，可以通过（在调用lock或acquire时成功返回），也可以等待（在调用lock或acquire时阻塞），还可以取消（在调用tryLock或tryAcquire时返回”假“，表示在指定的时间内锁是不可用的或者无法获取许可）。而且，这两个接口都支持中断、不可中断的以及限时的获取操作，并且也都支持等待线程执行公平或非公平的队列操作。</br>

原因：都实现了同一个基类AbstractQueuedSynchronizer（AQS）</br>




　　
　　
<h2>5.AbstractQueuedSynchronizer</h2>
最基本的操作：</br>
获取操作是一种依赖状态的操作，并且通常会阻塞（同步器判断当前状态是否允许获得操作，更新同步器的状态）</br>
释放并不是一个可阻塞的操作时，当执行“释放”操作时，所有在请求时被阻塞的线程都会开始执行</br>

状态管理（一个整数状态）：</br>
通过getState，setState以及compareAndSetState等protected类型方法来进行操作</br>
这个整数在不同子类表示任意状态。例：剩余的许可数量，任务状态</br>
子类可以添加额外状态</br>




<h2>6.java.util.concurrent 同步器类中的AQS</h2>
（1）ReentrantLock</br>
ReentrantLock只支持独占方式的获取操作，因此它实现了tryAcquire、tryRelease和isHeldExclusively</br>
ReentrantLock将同步状态用于保存锁获取操作的次数，或者正要释放锁的时候，才会修改这个变量</br>

（2）Semaphore与CountDownLatch</br>
　　Semaphore将AQS的同步状态用于保存当前可用许可的数量；CountDownLatch使用AQS的方式与Semaphore很相似，在同步状态中保存的是当前的计数值</br>

（3）FutureTask</br>
　　在FutureTask中，AQS同步状态被用来保存任务的状态</br>
　　FutureTask还维护一些额外的状态变量，用来保存计算结果或者抛出的异常</br>

（4）ReentrantReadWriteLock</br>
单个AQS子类将同时管理读取加锁和写入加锁</br>
ReentrantReadWriteLock使用了一个16位的状态来表示写入锁的计数，并且使用了另一个16位的状态来表示读取锁的计数</br>
在读取锁上的操作将使用共享的获取方法与释放方法，在写入锁上的操作将使用独占的获取方法与释放方法
AQS在内部维护了一个等待线程队列，其中记录了某个线程请求的是独占访问还是共享访问：写操作独占获取；读操作可使第一个写之前的读都获取</br>





<h1>第十五章  原子变量与非阻塞机制</h1>

<h2>1.锁的劣势</h2>
锁：独占方式访问共享变量，对变量的操作对其他获得同一个锁的线程可见</br>

劣势：</br>

请求锁失败，一些线程将被挂起并且在稍后恢复运行</br>
恢复执行时必须等其他的线程的执行时间片用完</br>
挂起和恢复的开销很大</br>
锁竞争存在开销</br>
优先级反转：被阻塞线程的优先级较高，而持有锁的线程优先级较低</br>
Volatile更轻量级，保证可见性，不会发生上下文切换和线程调度，但没有办法完成原子操作</br>


<h2>2.硬件对并发的支持</h2>
乐观的解决方法：借助冲突检查机制来判断在更新过程中是否存在来自其他线程的干扰，如果存在，这个操作将失败，并且可以重试（也可以不重试）</br>

针对多处理器操作而设计的处理器中提供了一些特殊指令：支持原子的测试并设置（Test-and-Set），获取并递增（Fetch-and-Increment）以及交换（Swap）等指令</br>

（1）比较并交换CAS——乐观技术</br>
当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其他线程都将失败（而不是挂起）</br>

竞争中失败，并且可以再次尝试，也可以放弃</br>

由于CAS能检测到来自其他线程的干扰（干扰结果为失败），因此即使不使用锁也能够实现原子的读-改-写操作序列</br>

（2）非阻塞的计数器</br>
CasCount不会发生阻塞，如果多个线程同时更新计数器，那么可能产生失败，并执行多次重试操作
为避免活锁，每次失败时，可以等一段时间再执行</br>
当竞争程度不高时，CasCount性能远高于基于锁的计数器</br>


（3）JVM对CAS的支持</br>
在原子变量类（例如java.util.concurrent.atomic中的AutomicXxx）中使用了这些底层的JVM支持为数字类型和引用类型提供了一种高效的CAS操作，而在java.util.concurrent中的大多数类在实现时则直接或间接地使用了这些原子变量类。</br>



<h2>3.原子变量类</h2>
原子变量比锁的粒度更细，量级更轻，直接利用硬件对并发的支持，性能比锁更好。原子变量相当于一种泛化的volatile变量，能够支持原子的和有条件的读-改-写操作.</br>

共有12个原子变量类，可分为4组：标量类（Scalar）、更新器类、数组类以及复合变量类.</br>

标量类（AtomicInteger、AutomicLong、AutomicBoolean以及AtomicReference）：模拟其他基本类型的原子变量，可以将short或byte等类型与int类型进行转换，以及使用floatToIntBits或doubleToLongBits来转换浮点数.</br>
原子数组类（AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray<E>）：volatile类型的数组仅在数组引用上具有volatile语义，而在其元素则没有.</br>
　　基本类型的包装类是不可修改的，而原子变量类是可修改的.</br>
　　
　　(1)原子变量是一种“更好的volatile”</br>
　　实现对多变量的非阻塞的先检查在执行操作。</br>
　　
　　(2)性能比较：锁与原子变量</br>
如果线程本地的计算量较少，那么在锁和原子变量上的竞争将非常激烈。如果线程本地的计算量较多，那么在锁和原子变量上的竞争会降低。</br>

在高度竞争的情况下，锁的性能将超过原子变量的性能（失败重试导致更激烈的竞争），但在更真实的情况下，原子变量的性能将超过锁的性能。</br>



<h2>4.非阻塞算法——一个线程的失败或挂起不会导致其他线程也失败或挂起</h2>

无锁算法——算法的每个步骤中都存在某个线程能够执行下去。</br>

在非阻塞算法中通常不会出现死锁和优先级反转问题（但可能会出现饥饿和活锁问题，因为在算法中会反复地重试）。</br>

　　创建非阻塞算法的关键在于，找出如何将原子修改的范围缩小到单个变量上，同时还要维护数据的一致性 。</br>

　　非阻塞算法的特性：某项工作的完成具有不确定性，必须重新执行。</br>

　　非阻塞算法中能确保线程安全性，因为compareAndSet像锁定机制一样，既能提供原子性，又能提供可见性。</br>
　　
　（1）非阻塞的栈——Treiber算法</br>
　（2）非阻塞的链表</br>
　（3）原子的域更新器</br>
　（4）ABA问题</br>
　
　
　
　<h1>第十六章 Java内存模型</h1>
　
<h2>1.什么是内存模型，为什么要使用它</h2>
　
如果缺少同步，那么将会有许多因素使得线程无法立即甚至永远看到一个线程的操作结果。</br>

编译器把变量保存在本地寄存器而不是内存中。</br>
编译器中生成的指令顺序，可以与源代码中的顺序不同。</br>
处理器采用乱序或并行的方式来执行指令。</br>
保存在处理器本地缓存中的值，对于其他处理器是不可见。</br>
在单线程中，只要程序的最终结果与在严格串行环境中执行的结果相同，那么上述所有操作都是允许的。</br>

在多线程中，JVM通过同步操作来找出这些协调操作将在何时发生。</br>

JMM规定了JVM必须遵循一组最小保证，这组保证规定了对变量的写入操作在何时将对其他线程可见。</br>


（1）平台的内存模型</br>
每个处理器都拥有自己的缓存，并且定期地与主内存进行协调，在不同的处理器架构中提供了不同级别的缓存一致性，即允许不同的处理器在任意时刻从同一个存储位置上看到不同的值。JVM通过在适当的位置上插入内存栅栏来屏蔽在JMM与底层平台内存模型之间的差异。Java程序不需要指定内存栅栏的位置，而只需通过正确地使用同步来找出何时将访问共享状态。</br>

（2）重排序</br>
　　各种使操作延迟或者看似乱序执行的不同原因，都可以归为重排序，内存级的重排序会使程序的行为变得不可预测。</br>
　　
　　
　　
（3）Java内存模式简介</br>

　　Java内存模型是通过各种操作来定义的，包括变量的读/写操作，监视器的加锁和释放操作，以及线程的启动和合并操作。</br>

　　JMM为程序中所有的操作定义了一个偏序关系，称为Happens-Before，使在正确同步的程序中不存在数据竞争（缺乏Happens-Before关系，那么JVM可以对它们任意地重排序）。</br>

程序顺序规则。如果程序中操作A在操作B之前，那么在线程中A操作将在B操作之前执行。</br>
监视器锁规则。在监视器锁上的解锁操作必须在同一个监视器锁上的加锁操作之前执行。（显式锁和内置锁在加锁和解锁等操作上有着相同的内存语义）。</br>
volatile变量规则。对volatile变量的写入操作必须在对该变量的读操作之前执行。（原子变量与volatile变量在读操作和写操作上有着相同的语义）。</br> 
线程启动规则。在线程上对Thread.start的调用必须在该线程中执行任何操作之前执行。</br>
线程结束规则。线程中的任何操作都必须在其他线程检测到该线程已经结束之前执行，或者从Thread.join中成功返回，或者在调用Thread.isAlive时返回false。</br>
中断规则。当一个线程在另一个线程上调用interrupt时，必须在被中断线程检测到interrupt调用之前执行（通过抛出InterruptException，或者调用isInterrupted和interrupted）。</br>
终结器规则。对象的构造函数必须在启动该对象的终结器之前执行完成。</br>
传递性。如果操作A在操作B之前执行，并且操作B在操作C之前执行，那么操作A必须在操作C之前执行。</br>


（4）借助同步</br>

”借助（Piggyback）“现有同步机制的可见性属性，对某个未被锁保护的变量的访问操作进行排序（不希望给对象加锁，而又想维护它的顺序）。</br>

 

Happens-Before排序包括：</br>

将一个元素放入一个线程安全容器的操作将在另一个线程从该容器中获得这个元素的操作之前执行。</br>
在CountDownLatch上的倒数操作将在线程从闭锁上的await方法返回之前执行。</br>
释放Semaphore许可的操作将在从该Semaphore上获得一个许可之前执行。</br>
Future表示的任务的所有操作将在从Future.get中返回之前执行。</br>
向Executor提交一个Runnable或Callable的操作将在任务开始执行之前执行。</br>
一个线程到达CyclicBarrier或Exchange的操作将在其他到达该栅栏或交换点的线程被释放之前执行。如果CyclicBarrier使用一个栅栏操作，那么到达栅栏的操作将在栅栏操作之前执行，而栅栏操作又会在线程从栅栏中释放之前执行。</br>


<h2>2.发布</h2>
造成不正确发布的真正原因："发布一个共享对象"与"另一个线程访问该对象"之间缺少一种Happens-Before的关系。</br>

（1）不安全的发布</br>

　　除了不可变对象以外，使用被另一个线程初始化的对象通常都是不安全的，除非对象的发布操作是在使用该对象的线程开始使用之前执。行</br>
　　
原因一：线程B看到了线程A发布了一半的对象。</br>

原因二：即使线程A初始化Resource实例之后再将resource设置为指向它，线程B仍可能看到对resource的写入操作将在对Resource各个域的写入操作之前发生。因为线程B看到的线程A中的操作顺序，可能与线程A执行这些操作时的顺序并不相同。</br>


（2）安全发布</br>

例：BlockingQueue的同步机制保证put在take后执行，A线程放入对象能保证B线程取出时是安全的。</br>

　　借助于类库中现在的同步容器、使用锁保护共享变量、或都使用共享的volatile类型变量，都可以保证对该变量的读取和写入是按照happens-before排序的。</br>

　　happens-before事实上可以比安全发布承诺更强的可见性与排序性。</br>
　　
（3）安全初始化模式</br>

方式一：加锁保证可见性与排序性，存在性能问题。</br>
方式二：提前初始化，可能造成浪费资源。</br>
方式三：延迟初始化，建议。</br>
方式四：双重加锁机制，注意保证volatile类型，否则出现一致性问题。</br>


<h2>3.初始化过程中的安全性</h2>

如果能确保初始化过程的安全性，被正确构造的不可变对象在没有同步的情况下也能安全地在多个线程之间共享。</br>
如果不能确保初始化的安全性，一些本应为不可变对象的值将会发生改变。</br>
初始化安全性只能保证通过final域可达的值从构造过程完成时可见性。对于通过非final域可达的值，或者在构成过程完成后可能改变的值，必须采用同步来确保可见性。</br>
　
　
